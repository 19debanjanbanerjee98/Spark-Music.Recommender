{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "artist_data_small.txt contains information about each user's unique artistId and its name. We read the file and create a map with key: artistId and value: artist Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to split artist Id and its name.\n",
    "def splitArtistName(line):\n",
    "    try:\n",
    "        id, name = line.split(\"\\t\")\n",
    "        return (int(id), name)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load text file where each line contains artist Id and its name.\n",
    "artistData = sc.textFile(\"artist_data_small.txt\")\n",
    "# Split artist id: name and store in a map. \n",
    "artistData = artistData.map(splitArtistName).filter(lambda x: x!=None).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioScrobbler has provided us with the a file which contains information about an artist's other alias' / misspelled names. We use this information to correct the user-artist information by replacing the aliases by its uniqueId. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load artist correct id and its aliases\n",
    "    2 columns: badid, goodid\n",
    "    known incorrectly spelt artists and the correct artist id. \n",
    "'''\n",
    "artistAlias = sc.textFile('artist_alias_small.txt')\n",
    "# Split Artist Alias data into (badId, goodId)\n",
    "def splitArtistAlias(line):\n",
    "    try:\n",
    "        # Catches error in data\n",
    "        badId, goodId = line.split(\"\\t\")\n",
    "        return (int(badId), int(goodId))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Create map badId: goodId\n",
    "\n",
    "artistAlias = artistAlias.map(splitArtistAlias).filter(lambda x: x!=None).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, user_artist_data_small.txt contains misspelled artistId. Hence we use the artistAlias map to correct the entries in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load data about user's music listening history\n",
    "Each line contains three features: userid, artistid, playcount\n",
    "'''\n",
    "userArtistData = sc.textFile(\"user_artist_data_small.txt\")\n",
    "\n",
    "# Return the corrected user information.\n",
    "def parseUserHistory(line):\n",
    "    try:\n",
    "        # Catch error in line\n",
    "        user, artist, count = line.split()\n",
    "        # Return the corrected user information.\n",
    "        if artist in artistAlias:\n",
    "            return (int(user), artistAlias[artist], int(count))\n",
    "        else:\n",
    "            return (int(user), int(artist), int(count))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create corrected user history RDD.\n",
    "userArtistData = userArtistData.map(parseUserHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since userArtistData would be used repeatedly, we might want to cache this to avoid re-computation of the same RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userArtistData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section creates a new RDD containing basic user listening stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userArtistPurge = userArtistData.map(lambda x: (x[0],x[2]))\n",
    "# Create an RDD storing user information in the form of (total play count of all artists combined for the current user, (userId of the current user, number of unique artists listened by user))\n",
    "songCountAgg = userArtistPurge.aggregateByKey((0,0), lambda a,b: (a[0] + b, a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1])).map(lambda x: (x[1][0], (x[0], x[1][1])))\n",
    "# Sort the RDD based on the total play counts so as to find the most active user.\n",
    "sortedCount = songCountAgg.sortByKey(False)\n",
    "# Find the top 3 user information\n",
    "sortedCountTop3 = sortedCount.take(3)\n",
    "\n",
    "# Print the top 3 user information.\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[0][1][0],sortedCountTop3[0][0], sortedCountTop3[0][0]/sortedCountTop3[0][1][1])\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[1][1][0],sortedCountTop3[1][0], sortedCountTop3[1][0]/sortedCountTop3[1][1][1])\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[2][1][0],sortedCountTop3[2][0], sortedCountTop3[2][0]/sortedCountTop3[2][1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
